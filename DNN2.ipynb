{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "2KgsqnsIPdxd"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "01ClEGd9Wez4"
      },
      "cell_type": "code",
      "source": [
        "#Loading training and testing files\n",
        "#Computing STFT on all the files\n",
        "s, sr = librosa.load('train_clean_male.wav', sr=None)\n",
        "S = librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "\n",
        "sn, sr = librosa.load('train_dirty_male.wav', sr=None)\n",
        "X = librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "\n",
        "x_test, sr = librosa.load('test_01.wav', sr=None)\n",
        "X_test = librosa.stft(x_test, n_fft=1024, hop_length=512)\n",
        "\n",
        "x_test2, sr = librosa.load('test_02.wav', sr=None)\n",
        "X_test2 = librosa.stft(x_test2, n_fft=1024, hop_length=512)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "64FCDoubWvoO"
      },
      "cell_type": "code",
      "source": [
        "#Calculating the magnitude of all the input files\n",
        "mag_S = np.abs(S)\n",
        "mag_X = np.abs(X)\n",
        "mag_X_test = np.abs(X_test)\n",
        "mag_X_test2 = np.abs(X_test2)\n",
        "\n",
        "#Defining model specifications\n",
        "learning_rate = 0.001\n",
        "act_layers = [tf.nn.relu, tf.nn.relu, tf.nn.relu, tf.nn.relu]\n",
        "neurons = [513, 513, 513, 513]\n",
        "num_layers = len(act_layers)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JMezPnXIW4Gv"
      },
      "cell_type": "code",
      "source": [
        "def getModel(x , act_layers , neurons):\n",
        "    num_layers = len(act_layers)\n",
        "    layers = [0]*num_layers\n",
        "\n",
        "    for i in range(0 , len(act_layers)):\n",
        "        if i == 0:\n",
        "            layers[i] = tf.keras.layers.Dense(units=neurons[i] , activation=act_layers[i]) # Removed 'x' and pass input when calling the layer\n",
        "        elif i < num_layers-1:\n",
        "            layers[i] = tf.keras.layers.Dense(units=neurons[i] , activation=act_layers[i]) # Removed 'layers[i-1]' and will pass input during call\n",
        "        else:\n",
        "            layers[i] = tf.keras.layers.Dense(units=neurons[i] , activation=act_layers[i]) # Removed 'layers[i-1]' and will pass input during call\n",
        "\n",
        "    #Chain the layers together by applying them sequentially to the input\n",
        "    output = x\n",
        "    for layer in layers:\n",
        "        output = layer(output)\n",
        "    return output # Return the output of the final layer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kyZl3kuBW9oO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "208e84db-6e93-47a4-8a0a-1289f7bc8f39"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.0005\n",
        "batch_size = 100\n",
        "epochs = 200\n",
        "\n",
        "# Placeholder data: Replace these with your actual data tensors\n",
        "# Assuming mag_X and mag_S are numpy arrays or tensors of shape (features, samples)\n",
        "mag_X = tf.random.normal([100, 2459])  # Example input: Replace with actual data\n",
        "mag_S = tf.random.normal([100, 2459])  # Example target: Replace with actual data\n",
        "\n",
        "# Model definition\n",
        "num_features = mag_X.shape[0]  # Number of features\n",
        "input_layer = tf.keras.layers.Input(shape=(num_features,), name=\"input\")\n",
        "hidden_layer1 = tf.keras.layers.Dense(128, activation=\"relu\", name=\"hidden1\")(input_layer)\n",
        "hidden_layer2 = tf.keras.layers.Dense(256, activation=\"relu\", name=\"hidden2\")(hidden_layer1)\n",
        "hidden_layer3 = tf.keras.layers.Dense(128, activation=\"relu\", name=\"hidden3\")(hidden_layer2)\n",
        "output_layer = tf.keras.layers.Dense(num_features, activation=None, name=\"output\")(hidden_layer3)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "# Loss function\n",
        "def loss_function(labels, predictions):\n",
        "    return tf.reduce_mean(tf.square(labels - predictions))\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    size = 0\n",
        "    for i in range(0, 2500, batch_size):\n",
        "        size += batch_size\n",
        "        if size <= 2459:\n",
        "            batch_x = mag_X[:, i:size]\n",
        "            batch_y = mag_S[:, i:size]\n",
        "        else:\n",
        "            batch_x = mag_X[:, i:2459]\n",
        "            batch_y = mag_S[:, i:2459]\n",
        "\n",
        "        # Gradient computation and weight updates\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Transpose using tf.transpose()\n",
        "            predictions = model(tf.transpose(batch_x), training=True)\n",
        "            loss_value = loss_function(tf.transpose(batch_y), predictions)\n",
        "\n",
        "        gradients = tape.gradient(loss_value, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    # Log loss every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss_value.numpy()}\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.0077227354049683\n",
            "Epoch 10, Loss: 0.9415057301521301\n",
            "Epoch 20, Loss: 0.8286869525909424\n",
            "Epoch 30, Loss: 0.7275855541229248\n",
            "Epoch 40, Loss: 0.6518456935882568\n",
            "Epoch 50, Loss: 0.5973954796791077\n",
            "Epoch 60, Loss: 0.5590300559997559\n",
            "Epoch 70, Loss: 0.5329704284667969\n",
            "Epoch 80, Loss: 0.5077674984931946\n",
            "Epoch 90, Loss: 0.48839032649993896\n",
            "Epoch 100, Loss: 0.47629687190055847\n",
            "Epoch 110, Loss: 0.46272584795951843\n",
            "Epoch 120, Loss: 0.44609010219573975\n",
            "Epoch 130, Loss: 0.4435802698135376\n",
            "Epoch 140, Loss: 0.43001654744148254\n",
            "Epoch 150, Loss: 0.4266510605812073\n",
            "Epoch 160, Loss: 0.41732853651046753\n",
            "Epoch 170, Loss: 0.4113408625125885\n",
            "Epoch 180, Loss: 0.4072929322719574\n",
            "Epoch 190, Loss: 0.40178999304771423\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the output from the given input, trained model and layer number\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Feedforward function\n",
        "def feedforward(input_data, model, layer_num):\n",
        "    # Ensure the input_data is a numpy array or tensor compatible with model\n",
        "    input_tensor = tf.convert_to_tensor(input_data, dtype=tf.float32)\n",
        "    intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.layers[layer_num].output)\n",
        "    output = intermediate_model(input_tensor)\n",
        "\n",
        "    return output.numpy()\n",
        "\n",
        "# Recovering the complex values of the file from the output of the model\n",
        "def recover_sound(X, mag_X, mag_output):\n",
        "    # Assuming X is the original signal and mag_X is the magnitude spectrogram\n",
        "    # Recovering the complex value by applying the predicted magnitude with original phase\n",
        "    phase_X = np.angle(X)  # Get the phase of X\n",
        "\n",
        "    # Pad mag_output to match X's shape using tf.pad()\n",
        "    pad_rows = X.shape[0] - mag_output.shape[0]\n",
        "    pad_cols = X.shape[1] - mag_output.shape[1]\n",
        "\n",
        "    # Ensure pad_rows and pad_cols are non-negative\n",
        "    pad_rows = max(0, pad_rows)\n",
        "    pad_cols = max(0, pad_cols)\n",
        "\n",
        "    mag_output = tf.pad(mag_output, [[0, pad_rows], [0, pad_cols]])\n",
        "\n",
        "    # Convert mag_output to NumPy array to perform multiplication\n",
        "    mag_output = mag_output.numpy()\n",
        "\n",
        "    recovered_complex = mag_output * np.exp(1j * phase_X)  # Recombine magnitude with original phase\n",
        "\n",
        "    # Perform an inverse STFT to recover the time-domain signal (if using STFT)\n",
        "    s_hat = np.fft.ifft(recovered_complex).real  # Assuming s_hat is in time-domain\n",
        "\n",
        "    return s_hat\n",
        "\n"
      ],
      "metadata": {
        "id": "oZKTDDpHozdv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "LL5MgYy-kVVw",
        "outputId": "5f451787-bb37-4e7d-9d79-f4e44ef3e9f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input (\u001b[38;5;33mInputLayer\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m12,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m33,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m12,900\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m91,748\u001b[0m (358.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,748</span> (358.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m91,748\u001b[0m (358.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,748</span> (358.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the model's output for test_01.wav\n",
        "# Calculate the number of features needed to maintain the total elements\n",
        "num_features_test1 = mag_X_test.shape[0]  # Get the original number of features\n",
        "num_samples_test1 = mag_X_test.shape[1]  # Get the number of samples\n",
        "\n",
        "# Transpose to match the expected input shape (None, 100)\n",
        "# The input shape should be (num_samples_test1, num_features)\n",
        "mag_X_test_reshaped = tf.transpose(mag_X_test)\n",
        "# Instead of padding, truncate the features to 100 if necessary\n",
        "mag_X_test_reshaped = mag_X_test_reshaped[:, :100]  # Truncate to 100 features\n",
        "\n",
        "# Predict using the model\n",
        "mag_output_test1 = model.predict(mag_X_test_reshaped)\n",
        "\n",
        "# Recover the sound from the model's output\n",
        "s_hat_test1 = recover_sound(X_test, mag_X_test, tf.transpose(mag_output_test1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHfweHzko5ry",
        "outputId": "9ccf2035-4c91-4392-e384-73e0dd570a53"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "cHKUBXAq3_C6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4bd8885-2a35-4f1d-806a-62cb8eaba48e"
      },
      "cell_type": "code",
      "source": [
        "## Computing the output from the model for both the test files\n",
        "# Assuming mag_X_test and mag_X_test2 are the processed data\n",
        "# Transpose and truncate mag_X_test to match the expected input shape\n",
        "mag_X_test_input = tf.transpose(mag_X_test)[:, :100]\n",
        "mag_X_test2_input = tf.transpose(mag_X_test2)[:, :100]\n",
        "\n",
        "s_hat_test1 = feedforward(mag_X_test_input, model, 2)\n",
        "s_hat_test2 = feedforward(mag_X_test2_input, model, 2)\n",
        "\n",
        "# Recovering the complex values of both the test files\n",
        "s_hat1 = recover_sound(X_test, mag_X_test, s_hat_test1.T)\n",
        "s_hat2 = recover_sound(X_test2, mag_X_test2, s_hat_test2.T)\n",
        "\n",
        "# Reconstructing the test files after removing noise\n",
        "import librosa\n",
        "import soundfile as sf # Make sure to import soundfile\n",
        "\n",
        "recon_sound1 = librosa.istft(s_hat1, hop_length=512, win_length=1024)\n",
        "sf.write('test_s_01_recons.wav', recon_sound1, sr)\n",
        "print(\"Reconstructed test_s_01_recons.wav saved successfully.\")\n",
        "\n",
        "recon_sound2 = librosa.istft(s_hat2, hop_length=512, win_length=1024)\n",
        "sf.write('test_s_02_recons.wav', recon_sound2, sr)\n",
        "print(\"Reconstructed test_s_02_recons.wav saved successfully.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed test_s_01_recons.wav saved successfully.\n",
            "Reconstructed test_s_02_recons.wav saved successfully.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "uKKJX2otZMB2"
      },
      "cell_type": "code",
      "source": [
        "#For testing purpose, feeding the model with train_dirty_male file\n",
        "#From the output generated, reconstructing the audio file\n",
        "s_hat_test3 = feedforward(tf.transpose(mag_X) , model , 2) # Changed mag_X.T to tf.transpose(mag_X) and output to model, 4 to 2\n",
        "s_hat3 = recover_sound(X, mag_X , s_hat_test3.T)\n",
        "recon_sound3 = librosa.istft(s_hat3 , hop_length=512 , win_length=1024)\n",
        "size_recon_sound3 = np.shape(recon_sound3)[0]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5z-fgfR8amj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "058ff295-5e09-4ea4-9abf-6f53211d522a"
      },
      "cell_type": "code",
      "source": [
        "#Once the audio file is generated, calculating the SNR value\n",
        "s = s[: size_recon_sound3]\n",
        "num = np.dot(s.T , s)\n",
        "den = np.dot((s - recon_sound3).T,(s - recon_sound3))\n",
        "SNR = 10 * np.log10(num/den)\n",
        "print('Value of SNR : ' + str(SNR))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value of SNR : -0.0010992574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gvMReE7gugn9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}